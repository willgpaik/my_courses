{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c4e373-8c7e-410a-a446-e282dd256f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13658aa0-97ac-4f1a-b8d3-70d649b5e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a44c379-dc31-4265-ab17-c1a697c9a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='../Data/', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c12516-988c-4607-a093-1206e3ee9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root='../Data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e216897-8d41-4fd5-87d6-a97914608867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../Data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27faff90-5901-40a2-9686-d06a7c84ad37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../Data/\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a02f3aff-0c5c-4836-9aea-f42729c74607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82de2774-2103-4b16-8dd3-3e5ddb2056d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 color channel, 6 filters (output channels, arbitrary), 3x3 kernel, stride=1\n",
    "conv1 = nn.Conv2d(1,6,3,1) # original img ---> 6 filters ---> pooling ---> conv2\n",
    "\n",
    "# 6 input filters from conv1, 16 filters (arbitrary), 3x3 kernel, stride=1\n",
    "conv2 = nn.Conv2d(6,16,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ecc0cc-9dec-423c-acf8-f0ce78379022",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d3667e-f457-448b-82f1-d1cfaa88da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (add dimension to batch size (1), 1, 28, 28)\n",
    "x = X_train.view(1, 1, 28, 28) # conver to ----> 4D batch (batch of 1 image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e94cfbdd-ad98-424e-bebe-a09295bf36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8ccffce-60f1-4ba4-849d-a9ea538f1dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 26, 26])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # (1 image, 6 filters, losing border info (28->26), same->26) because no paddings are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "591a7a10-2954-4e34-9dea-6489fa9467d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.max_pool2d(x,2,2) # (data, 2x2 kernel, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3740dc78-b6d8-4fe9-824a-d15dee46ebae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 13, 13])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # reduce the size by 2 (because of 2x2 kernel and stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56d9b7a9-2476-4670-8e81-722ebf8e763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bc4ab44-a055-4c84-be65-d43f39856eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 11, 11])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "061a19cd-b8bb-4d23-932a-71b446a452df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.max_pool2d(x,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dd7a4f0-d938-4109-b0a3-e44f0f29c22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79435747-767b-425f-95cd-064b3b7d79da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((28-2)/2-2)/2 # how to get 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efcc83cd-a372-45bc-8931-a4d918562c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,16*5*5).shape # keep first dimension, 16*5*5 to flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8af9d4fb-5f99-4f8a-a8fe-2106d5fc4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,3,1)\n",
    "        self.conv2 = nn.Conv2d(6,16,3,1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X,2,2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X,2,2)\n",
    "        X = X.view(-1,16*5*5)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3945fd97-74c0-4354-8513-19a997ca5dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionalNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc2d104b-ba1d-4472-914f-1b4b5fa8581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "6\n",
      "864\n",
      "16\n",
      "48000\n",
      "120\n",
      "10080\n",
      "84\n",
      "840\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.numel())\n",
    "\n",
    "# total = 60074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a150eb6d-5b51-4215-bd70-bbf90ee49976",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "beb1e226-4046-47d2-9e81-03bdd51cafe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 batch: 600 loss: 0.10585442930459976\n",
      "epoch: 0 batch: 1200 loss: 0.1937195211648941\n",
      "epoch: 0 batch: 1800 loss: 0.28246447443962097\n",
      "epoch: 0 batch: 2400 loss: 0.2788349390029907\n",
      "epoch: 0 batch: 3000 loss: 0.1059822216629982\n",
      "epoch: 0 batch: 3600 loss: 0.07784382998943329\n",
      "epoch: 0 batch: 4200 loss: 0.26412978768348694\n",
      "epoch: 0 batch: 4800 loss: 0.0032613431103527546\n",
      "epoch: 0 batch: 5400 loss: 0.04633064940571785\n",
      "epoch: 0 batch: 6000 loss: 0.007355888839811087\n",
      "epoch: 1 batch: 600 loss: 0.20316310226917267\n",
      "epoch: 1 batch: 1200 loss: 0.006854281760752201\n",
      "epoch: 1 batch: 1800 loss: 0.0408165343105793\n",
      "epoch: 1 batch: 2400 loss: 0.000346938002621755\n",
      "epoch: 1 batch: 3000 loss: 0.004845469258725643\n",
      "epoch: 1 batch: 3600 loss: 0.020094765350222588\n",
      "epoch: 1 batch: 4200 loss: 0.00847818423062563\n",
      "epoch: 1 batch: 4800 loss: 0.0010747266933321953\n",
      "epoch: 1 batch: 5400 loss: 0.011174002662301064\n",
      "epoch: 1 batch: 6000 loss: 0.00014427633141167462\n",
      "epoch: 2 batch: 600 loss: 0.0009847130859270692\n",
      "epoch: 2 batch: 1200 loss: 0.00023303143098019063\n",
      "epoch: 2 batch: 1800 loss: 0.01201515644788742\n",
      "epoch: 2 batch: 2400 loss: 0.007154446095228195\n",
      "epoch: 2 batch: 3000 loss: 0.0029539375100284815\n",
      "epoch: 2 batch: 3600 loss: 0.02139914408326149\n",
      "epoch: 2 batch: 4200 loss: 5.8028595958603546e-05\n",
      "epoch: 2 batch: 4800 loss: 0.6422830820083618\n",
      "epoch: 2 batch: 5400 loss: 0.029751639813184738\n",
      "epoch: 2 batch: 6000 loss: 0.23150840401649475\n",
      "epoch: 3 batch: 600 loss: 0.02705405093729496\n",
      "epoch: 3 batch: 1200 loss: 0.006193473935127258\n",
      "epoch: 3 batch: 1800 loss: 0.07087719440460205\n",
      "epoch: 3 batch: 2400 loss: 0.14140170812606812\n",
      "epoch: 3 batch: 3000 loss: 0.002584108617156744\n",
      "epoch: 3 batch: 3600 loss: 0.016794782131910324\n",
      "epoch: 3 batch: 4200 loss: 0.00029345203074626625\n",
      "epoch: 3 batch: 4800 loss: 0.0006458897842094302\n",
      "epoch: 3 batch: 5400 loss: 0.05298266559839249\n",
      "epoch: 3 batch: 6000 loss: 0.0002191780658904463\n",
      "epoch: 4 batch: 600 loss: 0.0017586108297109604\n",
      "epoch: 4 batch: 1200 loss: 0.0009855740936473012\n",
      "epoch: 4 batch: 1800 loss: 0.00023719700402580202\n",
      "epoch: 4 batch: 2400 loss: 0.04417189210653305\n",
      "epoch: 4 batch: 3000 loss: 5.9007852541981265e-06\n",
      "epoch: 4 batch: 3600 loss: 0.0006500337040051818\n",
      "epoch: 4 batch: 4200 loss: 0.12278984487056732\n",
      "epoch: 4 batch: 4800 loss: 4.282497684471309e-05\n",
      "epoch: 4 batch: 5400 loss: 8.18571716081351e-05\n",
      "epoch: 4 batch: 6000 loss: 0.008733296766877174\n",
      "training took 1.091416847705841 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# variables (trackers)\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "# for loop epochs\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "\n",
    "    # train\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b += 1\n",
    "\n",
    "        y_pred = model(X_train) # not flatten (no longer needed cuz 2d data is required for conv2d)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "        predicted = torch.max(y_pred.data,1)[1]\n",
    "        batch_corr = (predicted == y_train).sum() # true = 1 / false = 0\n",
    "        trn_corr += batch_corr\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if b%600 == 0:\n",
    "            print(f\"epoch: {i} batch: {b} loss: {loss.item()}\")\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "    train_correct.append(trn_corr)\n",
    "\n",
    "    # test\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            predicted = torch.max(y_val.data,1)[1]\n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "\n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss.item())\n",
    "    test_correct.append(tst_corr)\n",
    "\n",
    "\n",
    "current_time = time.time()\n",
    "total = current_time - start_time\n",
    "print(f\"training took {total/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4a914-c2b7-4050-9740-d87f8b75a706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
