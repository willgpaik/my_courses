{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsN12V6QmGO4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <h1>\n",
    "        Deep Q-Learning\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "\n",
    "In this notebook, we extend the Q-Learning algorithm to use function approximators (Neural Networks). The resulting algorithm is known as Deep Q-Learning.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "E4pxsu9-mPGv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    }
   ],
   "source": [
    "# @title Setup code (not important) - Run this cell by pressing \"Shift + Enter\"\n",
    "\n",
    "\n",
    "\n",
    "#!pip install -qq gym==0.23.0\n",
    "\n",
    "\n",
    "from typing import Tuple, Dict, Optional, Iterable, Callable\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import torch\n",
    "from matplotlib import animation\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.error import DependencyNotInstalled\n",
    "\n",
    "import pygame\n",
    "from pygame import gfxdraw\n",
    "\n",
    "\n",
    "class Maze(gym.Env):\n",
    "\n",
    "    def __init__(self, exploring_starts: bool = False,\n",
    "                 shaped_rewards: bool = False, size: int = 5) -> None:\n",
    "        super().__init__()\n",
    "        self.exploring_starts = exploring_starts\n",
    "        self.shaped_rewards = shaped_rewards\n",
    "        self.state = (size - 1, size - 1)\n",
    "        self.goal = (size - 1, size - 1)\n",
    "        self.maze = self._create_maze(size=size)\n",
    "        self.distances = self._compute_distances(self.goal, self.maze)\n",
    "        self.action_space = spaces.Discrete(n=4)\n",
    "        self.action_space.action_meanings = {0: 'UP', 1: 'RIGHT', 2: 'DOWN', 3: \"LEFT\"}\n",
    "        self.observation_space = spaces.MultiDiscrete([size, size])\n",
    "\n",
    "        self.screen = None\n",
    "        self.agent_transform = None\n",
    "\n",
    "    def step(self, action: int) -> Tuple[Tuple[int, int], float, bool, Dict]:\n",
    "        reward = self.compute_reward(self.state, action)\n",
    "        self.state = self._get_next_state(self.state, action)\n",
    "        done = self.state == self.goal\n",
    "        info = {}\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def reset(self) -> Tuple[int, int]:\n",
    "        if self.exploring_starts:\n",
    "            while self.state == self.goal:\n",
    "                self.state = tuple(self.observation_space.sample())\n",
    "        else:\n",
    "            self.state = (0, 0)\n",
    "        return self.state\n",
    "\n",
    "    def render(self, mode: str = 'human') -> Optional[np.ndarray]:\n",
    "        assert mode in ['human', 'rgb_array']\n",
    "\n",
    "        screen_size = 600\n",
    "        scale = screen_size / 5\n",
    "\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.Surface((screen_size, screen_size))\n",
    "\n",
    "        surf = pygame.Surface((screen_size, screen_size))\n",
    "        surf.fill((22, 36, 71))\n",
    "\n",
    "\n",
    "        for row in range(5):\n",
    "            for col in range(5):\n",
    "\n",
    "                state = (row, col)\n",
    "                for next_state in [(row + 1, col), (row - 1, col), (row, col + 1), (row, col - 1)]:\n",
    "                    if next_state not in self.maze[state]:\n",
    "\n",
    "                        # Add the geometry of the edges and walls (i.e. the boundaries between\n",
    "                        # adjacent squares that are not connected).\n",
    "                        row_diff, col_diff = np.subtract(next_state, state)\n",
    "                        left = (col + (col_diff > 0)) * scale - 2 * (col_diff != 0)\n",
    "                        right = ((col + 1) - (col_diff < 0)) * scale + 2 * (col_diff != 0)\n",
    "                        top = (5 - (row + (row_diff > 0))) * scale - 2 * (row_diff != 0)\n",
    "                        bottom = (5 - ((row + 1) - (row_diff < 0))) * scale + 2 * (row_diff != 0)\n",
    "\n",
    "                        gfxdraw.filled_polygon(surf, [(left, bottom), (left, top), (right, top), (right, bottom)], (255, 255, 255))\n",
    "\n",
    "        # Add the geometry of the goal square to the viewer.\n",
    "        left, right, top, bottom = scale * 4 + 10, scale * 5 - 10, scale - 10, 10\n",
    "        gfxdraw.filled_polygon(surf, [(left, bottom), (left, top), (right, top), (right, bottom)], (40, 199, 172))\n",
    "\n",
    "        # Add the geometry of the agent to the viewer.\n",
    "        agent_row = int(screen_size - scale * (self.state[0] + .5))\n",
    "        agent_col = int(scale * (self.state[1] + .5))\n",
    "        gfxdraw.filled_circle(surf, agent_col, agent_row, int(scale * .6 / 2), (228, 63, 90))\n",
    "\n",
    "        surf = pygame.transform.flip(surf, False, True)\n",
    "        self.screen.blit(surf, (0, 0))\n",
    "\n",
    "        return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "\n",
    "    def close(self) -> None:\n",
    "        if self.screen is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.screen = None\n",
    "\n",
    "    def compute_reward(self, state: Tuple[int, int], action: int) -> float:\n",
    "        next_state = self._get_next_state(state, action)\n",
    "        if self.shaped_rewards:\n",
    "            return - (self.distances[next_state] / self.distances.max())\n",
    "        return - float(state != self.goal)\n",
    "\n",
    "    def simulate_step(self, state: Tuple[int, int], action: int):\n",
    "        reward = self.compute_reward(state, action)\n",
    "        next_state = self._get_next_state(state, action)\n",
    "        done = next_state == self.goal\n",
    "        info = {}\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "    def _get_next_state(self, state: Tuple[int, int], action: int) -> Tuple[int, int]:\n",
    "        if action == 0:\n",
    "            next_state = (state[0] - 1, state[1])\n",
    "        elif action == 1:\n",
    "            next_state = (state[0], state[1] + 1)\n",
    "        elif action == 2:\n",
    "            next_state = (state[0] + 1, state[1])\n",
    "        elif action == 3:\n",
    "            next_state = (state[0], state[1] - 1)\n",
    "        else:\n",
    "            raise ValueError(\"Action value not supported:\", action)\n",
    "        if next_state in self.maze[state]:\n",
    "            return next_state\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_maze(size: int) -> Dict[Tuple[int, int], Iterable[Tuple[int, int]]]:\n",
    "        maze = {(row, col): [(row - 1, col), (row + 1, col), (row, col - 1), (row, col + 1)]\n",
    "                for row in range(size) for col in range(size)}\n",
    "\n",
    "        left_edges = [[(row, 0), (row, -1)] for row in range(size)]\n",
    "        right_edges = [[(row, size - 1), (row, size)] for row in range(size)]\n",
    "        upper_edges = [[(0, col), (-1, col)] for col in range(size)]\n",
    "        lower_edges = [[(size - 1, col), (size, col)] for col in range(size)]\n",
    "        walls = [\n",
    "            [(1, 0), (1, 1)], [(2, 0), (2, 1)], [(3, 0), (3, 1)],\n",
    "            [(1, 1), (1, 2)], [(2, 1), (2, 2)], [(3, 1), (3, 2)],\n",
    "            [(3, 1), (4, 1)], [(0, 2), (1, 2)], [(1, 2), (1, 3)],\n",
    "            [(2, 2), (3, 2)], [(2, 3), (3, 3)], [(2, 4), (3, 4)],\n",
    "            [(4, 2), (4, 3)], [(1, 3), (1, 4)], [(2, 3), (2, 4)],\n",
    "        ]\n",
    "\n",
    "        obstacles = upper_edges + lower_edges + left_edges + right_edges + walls\n",
    "\n",
    "        for src, dst in obstacles:\n",
    "            maze[src].remove(dst)\n",
    "\n",
    "            if dst in maze:\n",
    "                maze[dst].remove(src)\n",
    "\n",
    "        return maze\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_distances(goal: Tuple[int, int],\n",
    "                           maze: Dict[Tuple[int, int], Iterable[Tuple[int, int]]]) -> np.ndarray:\n",
    "        distances = np.full((5, 5), np.inf)\n",
    "        visited = set()\n",
    "        distances[goal] = 0.\n",
    "\n",
    "        while visited != set(maze):\n",
    "            sorted_dst = [(v // 5, v % 5) for v in distances.argsort(axis=None)]\n",
    "            closest = next(x for x in sorted_dst if x not in visited)\n",
    "            visited.add(closest)\n",
    "\n",
    "            for neighbour in maze[closest]:\n",
    "                distances[neighbour] = min(distances[neighbour], distances[closest] + 1)\n",
    "        return distances\n",
    "\n",
    "\n",
    "def display_video(frames):\n",
    "    # Copied from: https://colab.research.google.com/github/deepmind/dm_control/blob/master/tutorial.ipynb\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use('Agg')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    matplotlib.use(orig_backend)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    im = ax.imshow(frames[0])\n",
    "    def update(frame):\n",
    "        im.set_data(frame)\n",
    "        return [im]\n",
    "    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
    "                                    interval=50, blit=True, repeat=False)\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "\n",
    "def test_agent(env, policy, episodes=10):\n",
    "    frames = []\n",
    "    for episode in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        frames.append(env.render(mode=\"rgb_array\"))\n",
    "\n",
    "        while not done:\n",
    "            p = policy(state)\n",
    "            if isinstance(p, np.ndarray):\n",
    "                action = np.random.choice(4, p=p)\n",
    "            else:\n",
    "                action = p\n",
    "            next_state, reward, done, _, extra_info = env.step(action)\n",
    "            img = env.render(mode=\"rgb_array\")\n",
    "            frames.append(img)\n",
    "            state = next_state\n",
    "\n",
    "    return display_video(frames)\n",
    "\n",
    "\n",
    "def seed_everything(env: gym.Env, seed: int = 42) -> None:\n",
    "    #env.seed(seed)\n",
    "    env.reset(seed=seed)\n",
    "    env.action_space.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def plot_stats(stats):\n",
    "    rows = len(stats)\n",
    "    cols = 1\n",
    "\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(12, 6))\n",
    "\n",
    "    for i, key in enumerate(stats):\n",
    "        vals = stats[key]\n",
    "        vals = [np.mean(vals[i-10:i+10]) for i in range(10, len(vals)-10)]\n",
    "        if len(stats) > 1:\n",
    "            ax[i].plot(range(len(vals)), vals)\n",
    "            ax[i].set_title(key, size=18)\n",
    "        else:\n",
    "            ax.plot(range(len(vals)), vals)\n",
    "            ax.set_title(key, size=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cost_to_go(env, q_network, xlabel=None, ylabel=None):\n",
    "    highx, highy = env.observation_space.high\n",
    "    lowx, lowy = env.observation_space.low\n",
    "    X = torch.linspace(lowx, highx, 100)\n",
    "    Y = torch.linspace(lowy, highy, 100)\n",
    "    X, Y = torch.meshgrid(X, Y)\n",
    "\n",
    "    q_net_input = torch.stack([X.flatten(), Y.flatten()], dim=-1)\n",
    "    Z = - q_network(q_net_input).max(dim=-1, keepdim=True)[0]\n",
    "    Z = Z.reshape(100, 100).detach().numpy()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='jet', linewidth=0, antialiased=False)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    ax.set_xlabel(xlabel, size=14)\n",
    "    ax.set_ylabel(ylabel, size=14)\n",
    "    ax.set_title(\"Estimated cost-to-go\", size=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_max_q(env, q_network, xlabel=None, ylabel=None, action_labels=[]):\n",
    "    highx, highy = env.observation_space.high\n",
    "    lowx, lowy = env.observation_space.low\n",
    "    X = torch.linspace(lowx, highx, 100)\n",
    "    Y = torch.linspace(lowy, highy, 100)\n",
    "    X, Y = torch.meshgrid(X, Y)\n",
    "    q_net_input = torch.stack([X.flatten(), Y.flatten()], dim=-1)\n",
    "    Z = q_network(q_net_input).argmax(dim=-1, keepdim=True)\n",
    "    Z = Z.reshape(100, 100).T.detach().numpy()\n",
    "    values = np.unique(Z.ravel())\n",
    "    values.sort()\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.xlabel(xlabel, size=14)\n",
    "    plt.ylabel(ylabel, size=14)\n",
    "    plt.title(\"Optimal action\", size=18)\n",
    "\n",
    "    im = plt.imshow(Z, cmap='jet')\n",
    "    colors = [im.cmap(im.norm(value)) for value in values]\n",
    "    patches = [mpatches.Patch(color=color, label=label) for color, label in zip(colors, action_labels)]\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXh1rh7YmGO7"
   },
   "source": [
    "## Import the necessary software libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yIz69YQomGO7"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import gymnasium  as gym\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn as nn\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CYkeXJCmGO8"
   },
   "source": [
    "## Create and prepare the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PV0R_SojmGO8"
   },
   "source": [
    "### Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fCeFY5FamGO8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpaik/.conda/envs/pytorch/lib/python3.12/site-packages/gymnasium/envs/registration.py:517: DeprecationWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f266e3f4b00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0', render_mode='rgb_array')\n",
    "env.reset()\n",
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi2Tk4qumGO9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lRro8JfmGO9"
   },
   "source": [
    "### Prepare the environment to work with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tr4VrlvjmGO9"
   },
   "outputs": [],
   "source": [
    "class PreprocessEnv(gym.Wrapper):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        return torch.from_numpy(obs).unsqueeze(dim=0).float()\n",
    "\n",
    "    def step(self, action):\n",
    "        action = action.item()\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "        next_state = torch.from_numpy(next_state).unsqueeze(dim=0).float()\n",
    "        reward = torch.tensor(reward).view(1, -1).float()\n",
    "        done = torch.tensor(done).view(1, -1)\n",
    "        return next_state, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v87pAharmGO9"
   },
   "outputs": [],
   "source": [
    "env = PreprocessEnv(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82nlQI26mGO9"
   },
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "action = torch.tensor(0)\n",
    "next_state, reward, done, _ = env.step(action)\n",
    "print(f\"Sample state: {state}\")\n",
    "print(f\"Next state: {next_state}, Reward: {reward}, Done: {done}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aDkOllmmGO9"
   },
   "source": [
    "## Create the Q-Network and policy\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lPti0REmGO-"
   },
   "source": [
    "### Create the Q-Network: $\\hat q(s,a| \\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABFi9TU9mGO-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PH4vUbtUmGO-"
   },
   "source": [
    "### Create the target Q-Network: $\\hat q(s, a|\\theta_{targ})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGqbOfrEmGO-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJ1lw7UymGO-"
   },
   "source": [
    "### Create the exploratory policy: $b(s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6E9kafymGO-"
   },
   "outputs": [],
   "source": [
    "def policy(state, epsilon=0.):\n",
    "    if torch.rand(1) < epsilon:\n",
    "        return torch.randint(num_actions, (1, 1))\n",
    "    else:\n",
    "        av = q_network(state).detach()\n",
    "        return torch.argmax(av, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVHtSSQymGO-"
   },
   "source": [
    "## Create the Experience Replay buffer\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center\">\n",
    "    <p>A simple buffer that stores transitions of arbitrary values, adapted from\n",
    "    <a href=\"https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html#training\">this source.</a></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjpSAtp4mGO-"
   },
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, capacity=100000):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def insert(self, transition):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = transition\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        assert self.can_sample(batch_size)\n",
    "\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        batch = zip(*batch)\n",
    "        return [torch.cat(items) for items in batch]\n",
    "\n",
    "    def can_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size * 10\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfIPpqjJmGO-",
    "scrolled": false
   },
   "source": [
    "## Implement the algorithm\n",
    "\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VxwD6svmGO_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbi8PEzlmGO_",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-3XR-_OmGO_"
   },
   "source": [
    "## Show results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCMwXERHmGO_"
   },
   "source": [
    "### Plot execution stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWrIfjzkmGO_"
   },
   "outputs": [],
   "source": [
    "plot_stats(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpLObvs5mGO_"
   },
   "source": [
    "### Test the resulting agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKyHEYyemGO_"
   },
   "outputs": [],
   "source": [
    "test_agent(env, policy, episodes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KK-lKC9RmGO_"
   },
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5y5r_670mGO_"
   },
   "source": [
    "[[1] Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
